{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f03f952c-4c8c-4c57-a036-2959976d2cea",
   "metadata": {},
   "source": [
    "## 어텐션을 이용한 텍스트 요약(Text Summarization with Attention mechanism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33efce58-8f17-4fcb-b1a7-248a8f6023b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "np.random.seed(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae16b7a1-b82d-4680-8fac-7b7932651bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 리뷰 개수 : 100000\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/snap/amazon-fine-food-reviews\n",
    "data = pd.read_csv('./data/Reviews.csv', nrows = 100000)\n",
    "print('전체 리뷰 개수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f1b34df-e8f2-4e76-94ed-92f9779d19e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>Not as Advertised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>Cough Medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>Great taffy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                Summary\n",
       "0  I have bought several of the Vitality canned d...  Good Quality Dog Food\n",
       "1  Product arrived labeled as Jumbo Salted Peanut...      Not as Advertised\n",
       "2  This is a confection that has been around a fe...  \"Delight\" says it all\n",
       "3  If you are looking for the secret ingredient i...         Cough Medicine\n",
       "4  Great taffy at a great price.  There was a wid...            Great taffy"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['Text','Summary']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21b95f5c-327c-4d26-8657-faacb8bc962a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3582</th>\n",
       "      <td>I rarely eat anything but whole wheat pasta, b...</td>\n",
       "      <td>reminds me of Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60498</th>\n",
       "      <td>I absolutely love 5-hour ENERGY! I use it afte...</td>\n",
       "      <td>5-hour ENERGY Highly Recommend!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53227</th>\n",
       "      <td>this chocolate is a true treat to eat, perfect...</td>\n",
       "      <td>supreme chocolate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21333</th>\n",
       "      <td>Greenies are very muched loved as a tatsy Trea...</td>\n",
       "      <td>Excellent Teeth Cleaner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3885</th>\n",
       "      <td>I love these noodles.  They are really great f...</td>\n",
       "      <td>Great and good price!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51521</th>\n",
       "      <td>These are great! As a lover of all chips I'm s...</td>\n",
       "      <td>Delicious, just like Salt and Vinegar Chips!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84261</th>\n",
       "      <td>Like other customers I divide these into handf...</td>\n",
       "      <td>Great snack, great value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10685</th>\n",
       "      <td>I recommend this instead for the same price: &lt;...</td>\n",
       "      <td>It's ok, but certainly not worth the cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59948</th>\n",
       "      <td>The noodles were all very broken, but the tast...</td>\n",
       "      <td>Knorr's beef noodles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41032</th>\n",
       "      <td>Despite claiming they use the \"finest ingredie...</td>\n",
       "      <td>HORRIBLE INGREDIENTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  \\\n",
       "3582   I rarely eat anything but whole wheat pasta, b...   \n",
       "60498  I absolutely love 5-hour ENERGY! I use it afte...   \n",
       "53227  this chocolate is a true treat to eat, perfect...   \n",
       "21333  Greenies are very muched loved as a tatsy Trea...   \n",
       "3885   I love these noodles.  They are really great f...   \n",
       "51521  These are great! As a lover of all chips I'm s...   \n",
       "84261  Like other customers I divide these into handf...   \n",
       "10685  I recommend this instead for the same price: <...   \n",
       "59948  The noodles were all very broken, but the tast...   \n",
       "41032  Despite claiming they use the \"finest ingredie...   \n",
       "\n",
       "                                            Summary  \n",
       "3582                            reminds me of Italy  \n",
       "60498               5-hour ENERGY Highly Recommend!  \n",
       "53227                             supreme chocolate  \n",
       "21333                       Excellent Teeth Cleaner  \n",
       "3885                          Great and good price!  \n",
       "51521  Delicious, just like Salt and Vinegar Chips!  \n",
       "84261                      Great snack, great value  \n",
       "10685     It's ok, but certainly not worth the cost  \n",
       "59948                          Knorr's beef noodles  \n",
       "41032                          HORRIBLE INGREDIENTS  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 랜덤으로 10개의 샘플 출력\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66b28c68-510d-4882-8968-8d08b7df921c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 열에서 중복을 배제한 유일한 샘플의 수 : 88426\n",
      "Summary 열에서 중복을 배제한 유일한 샘플의 수 : 72348\n"
     ]
    }
   ],
   "source": [
    "print('Text 열에서 중복을 배제한 유일한 샘플의 수 :', data['Text'].nunique())\n",
    "print('Summary 열에서 중복을 배제한 유일한 샘플의 수 :', data['Summary'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df96b479-2596-4ea8-834b-53bf9e6b1e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88426\n"
     ]
    }
   ],
   "source": [
    "# text 열에서 중복인 내용이 있다면 중복 제거\n",
    "data.drop_duplicates(subset=['Text'], inplace=True)\n",
    "print(\"전체 샘플수 :\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31a63d5e-68ae-4720-b83d-b8b4d0a0ba22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text       0\n",
      "Summary    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum()) # NuLL 존재 유무 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6fbec2fb-4dd6-46b1-828e-0578513c93cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88425\n"
     ]
    }
   ],
   "source": [
    "# Null 값을 가진 샘플 제거\n",
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07ed875c-833e-4954-9795-937d8ca820a7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "# 전처리 함수 내 사용\n",
    "contractions = {\"'cause\": 'because',\n",
    " \"I'd\": 'I would',\n",
    " \"I'd've\": 'I would have',\n",
    " \"I'll\": 'I will',\n",
    " \"I'll've\": 'I will have',\n",
    " \"I'm\": 'I am',\n",
    " \"I've\": 'I have',\n",
    " \"ain't\": 'is not',\n",
    " \"aren't\": 'are not',\n",
    " \"can't\": 'cannot',\n",
    " \"could've\": 'could have',\n",
    " \"couldn't\": 'could not',\n",
    " \"didn't\": 'did not',\n",
    " \"doesn't\": 'does not',\n",
    " \"don't\": 'do not',\n",
    " \"hadn't\": 'had not',\n",
    " \"hasn't\": 'has not',\n",
    " \"haven't\": 'have not',\n",
    " \"he'd\": 'he would',\n",
    " \"he'll\": 'he will',\n",
    " \"he's\": 'he is',\n",
    " \"here's\": 'here is',\n",
    " \"how'd\": 'how did',\n",
    " \"how'd'y\": 'how do you',\n",
    " \"how'll\": 'how will',\n",
    " \"how's\": 'how is',\n",
    " \"i'd\": 'i would',\n",
    " \"i'd've\": 'i would have',\n",
    " \"i'll\": 'i will',\n",
    " \"i'll've\": 'i will have',\n",
    " \"i'm\": 'i am',\n",
    " \"i've\": 'i have',\n",
    " \"isn't\": 'is not',\n",
    " \"it'd\": 'it would',\n",
    " \"it'd've\": 'it would have',\n",
    " \"it'll\": 'it will',\n",
    " \"it'll've\": 'it will have',\n",
    " \"it's\": 'it is',\n",
    " \"let's\": 'let us',\n",
    " \"ma'am\": 'madam',\n",
    " \"mayn't\": 'may not',\n",
    " \"might've\": 'might have',\n",
    " \"mightn't\": 'might not',\n",
    " \"mightn't've\": 'might not have',\n",
    " \"must've\": 'must have',\n",
    " \"mustn't\": 'must not',\n",
    " \"mustn't've\": 'must not have',\n",
    " \"needn't\": 'need not',\n",
    " \"needn't've\": 'need not have',\n",
    " \"o'clock\": 'of the clock',\n",
    " \"oughtn't\": 'ought not',\n",
    " \"oughtn't've\": 'ought not have',\n",
    " \"sha'n't\": 'shall not',\n",
    " \"shan't\": 'shall not',\n",
    " \"shan't've\": 'shall not have',\n",
    " \"she'd\": 'she would',\n",
    " \"she'd've\": 'she would have',\n",
    " \"she'll\": 'she will',\n",
    " \"she'll've\": 'she will have',\n",
    " \"she's\": 'she is',\n",
    " \"should've\": 'should have',\n",
    " \"shouldn't\": 'should not',\n",
    " \"shouldn't've\": 'should not have',\n",
    " \"so's\": 'so as',\n",
    " \"so've\": 'so have',\n",
    " \"that'd\": 'that would',\n",
    " \"that'd've\": 'that would have',\n",
    " \"that's\": 'that is',\n",
    " \"there'd\": 'there would',\n",
    " \"there'd've\": 'there would have',\n",
    " \"there's\": 'there is',\n",
    " \"they'd\": 'they would',\n",
    " \"they'd've\": 'they would have',\n",
    " \"they'll\": 'they will',\n",
    " \"they'll've\": 'they will have',\n",
    " \"they're\": 'they are',\n",
    " \"they've\": 'they have',\n",
    " \"this's\": 'this is',\n",
    " \"to've\": 'to have',\n",
    " \"wasn't\": 'was not',\n",
    " \"we'd\": 'we would',\n",
    " \"we'd've\": 'we would have',\n",
    " \"we'll\": 'we will',\n",
    " \"we'll've\": 'we will have',\n",
    " \"we're\": 'we are',\n",
    " \"we've\": 'we have',\n",
    " \"weren't\": 'were not',\n",
    " \"what'll\": 'what will',\n",
    " \"what'll've\": 'what will have',\n",
    " \"what're\": 'what are',\n",
    " \"what's\": 'what is',\n",
    " \"what've\": 'what have',\n",
    " \"when's\": 'when is',\n",
    " \"when've\": 'when have',\n",
    " \"where'd\": 'where did',\n",
    " \"where's\": 'where is',\n",
    " \"where've\": 'where have',\n",
    " \"who'll\": 'who will',\n",
    " \"who'll've\": 'who will have',\n",
    " \"who's\": 'who is',\n",
    " \"who've\": 'who have',\n",
    " \"why's\": 'why is',\n",
    " \"why've\": 'why have',\n",
    " \"will've\": 'will have',\n",
    " \"won't\": 'will not',\n",
    " \"won't've\": 'will not have',\n",
    " \"would've\": 'would have',\n",
    " \"wouldn't\": 'would not',\n",
    " \"wouldn't've\": 'would not have',\n",
    " \"y'all\": 'you all',\n",
    " \"y'all'd\": 'you all would',\n",
    " \"y'all'd've\": 'you all would have',\n",
    " \"y'all're\": 'you all are',\n",
    " \"y'all've\": 'you all have',\n",
    " \"you'd\": 'you would',\n",
    " \"you'd've\": 'you would have',\n",
    " \"you'll\": 'you will',\n",
    " \"you'll've\": 'you will have',\n",
    " \"you're\": 'you are',\n",
    " \"you've\": 'you have'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b087a5f9-b93a-4030-ac2f-2ed928490ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "{\"should've\", 'no', \"you've\", 'ourselves', 've', 'them', 'shan', 'me', 'has', \"shouldn't\", 'him', 'i', 'so', 'myself', 'am', 'which', 'have', 'ma', 'hers', 'it', 'for', 'all', 'hadn', \"won't\", 'theirs', \"wouldn't\", 'aren', 'its', \"weren't\", 'wouldn', 'being', \"you'll\", \"mightn't\", 'of', 'is', 'at', 'haven', 'they', 'most', \"she's\", 'or', 'should', 'as', 'why', 'themselves', 'isn', 'be', 'doing', \"doesn't\", 'those', 'his', 'in', 'now', 'under', 'after', 'here', 'where', 'just', 'if', 'yourselves', \"that'll\", 'we', \"mustn't\", 're', 'himself', 's', 'he', 'y', 'because', 'my', 'from', 'too', 'there', 'few', \"aren't\", 'both', 'until', 'the', 'your', 'd', 'ours', 'same', 'out', 'what', 'you', \"shan't\", 'mustn', 'between', \"you're\", \"wasn't\", 'yours', 'did', \"needn't\", \"isn't\", \"couldn't\", 'down', 'how', 'won', 'against', 'an', 'then', 'and', 'during', 'off', \"didn't\", 'before', \"hadn't\", 'been', 'only', 't', 'who', 'had', 'below', 'once', 'didn', 'this', 'itself', 'to', 'herself', 'that', \"it's\", \"hasn't\", 'very', 'through', 'not', 'does', 'her', 'any', \"haven't\", 'our', 'needn', 'do', 'wasn', 'above', 'further', 'with', 'when', 'into', 'over', 'll', 'yourself', 'can', 'while', 'up', 'will', 'were', 'such', 'she', 'was', 'by', 'their', 'whom', 'a', 'other', 'are', 'these', 'again', 'nor', 'on', 'than', 'each', 'own', 'having', 'about', 'hasn', 'but', 'couldn', 'mightn', 'doesn', 'weren', \"don't\", \"you'd\", 'shouldn', 'some', 'ain', 'don', 'm', 'o', 'more'}\n"
     ]
    }
   ],
   "source": [
    "# NLTK의 불용어\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print('불용어 개수 :', len(stop_words))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c31caff7-e547-45f2-9ddf-974faa7f5629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords = True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열  제거 Ex) my husband (and myself) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\",sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "\n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stop_words if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15dea1ce-3d34-441a-9672-9b4ac8c919ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything bought great infact ordered twice third ordered wasfor mother father\n",
      "great way to start the day\n"
     ]
    }
   ],
   "source": [
    "# 전처리 함수 확인\n",
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "temp_summary = 'Great way to start (or finish) the day!!!'\n",
    "print(preprocess_sentence(temp_text))\n",
    "print(preprocess_sentence(temp_summary, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "adabc918-32cb-48e1-8d8a-dcb029aa60f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\intown\\lib\\site-packages\\bs4\\__init__.py:439: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better',\n",
       " 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo',\n",
       " 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch',\n",
       " 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal',\n",
       " 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text 열 전처리\n",
    "clean_text = []\n",
    "for s in data['Text']:\n",
    "    clean_text.append(preprocess_sentence(s))\n",
    "clean_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81d70ed6-d3ff-4558-a3dc-7ef04a33ea01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\intown\\lib\\site-packages\\bs4\\__init__.py:408: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['good quality dog food',\n",
       " 'not as advertised',\n",
       " 'delight says it all',\n",
       " 'cough medicine',\n",
       " 'great taffy']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary 열 전처리\n",
    "clean_summary = []\n",
    "for s in data['Summary']:\n",
    "    clean_summary.append(preprocess_sentence(s, 0))\n",
    "clean_summary[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4fc314cc-e02d-4e98-91f6-65b063ded020",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Text'] = clean_text\n",
    "data['Summary'] = clean_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "280c1905-661c-4f9c-be36-c08a930a80c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text        0\n",
      "Summary    70\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 길이가 공백인 샘플은 NULL 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc1ab34a-f7e2-47e3-a908-3516f0fee1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88355\n"
     ]
    }
   ],
   "source": [
    "data.dropna(axis = 0, inplace = True)\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "21c8143c-4571-40c6-84bb-d9112747ad44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 2\n",
      "텍스트의 최대 길이 : 1235\n",
      "텍스트의 평균 길이 : 38.792428272310566\n",
      "요약의 최소 길이 : 1\n",
      "요약의 최대 길이 : 28\n",
      "요약의 평균 길이 : 4.010729443721352\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "text_len = [len(s.split()) for s in data['Text']]\n",
    "summary_len = [len(s.split()) for s in data['Summary']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(summary_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(summary_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(summary_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(summary_len)\n",
    "plt.title('Summary')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('Text')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Summary')\n",
    "plt.hist(summary_len, bins=40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Text')\n",
    "plt.hist(text_len, bins=40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2432474b-f7c0-4cfa-8b9c-b9335b986aac",
   "metadata": {},
   "source": [
    "원문 텍스트는 대체적으로 100이하의 길이를 가집니다. 또한, 평균 길이는 38입니다. 요약의 경우에는 대체적으로 15이하의 길이를 가지며 평균 길이는 4입니다. 여기서 패딩의 길이를 정하겠습니다. 평균 길이보다는 크게 잡아 각각 50과 8로 결정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cbc9d432-fbbd-4ae6-ab64-5975cba941dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_max_len = 50\n",
    "summary_max_len = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d7346cbf-8bcc-4055-80d5-556e5b20d7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce337d31-d290-4db9-8618-3356584f6006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 50 이하인 샘플의 비율: 0.7745119121724859\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(text_max_len, data['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f18ab927-9b71-47b1-a417-39f49b325d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 8 이하인 샘플의 비율: 0.9424593967517402\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(summary_max_len, data['Summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ce62ff5e-c492-4f8e-90bb-9d36a770614f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 65818\n"
     ]
    }
   ],
   "source": [
    "data = data[data['Text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['Summary'].apply(lambda x: len(x.split()) <= summary_max_len)]\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec200dc5-66db-4f0d-a3c3-c2d1a58ac53f",
   "metadata": {},
   "source": [
    "seq2seq 훈련을 위해서는 디코더의 입력과 레이블에 시작 토큰과 종료 토큰을 추가할 필요가 있습니다. 시작 토큰은 'sostoken', 종료 토큰은 'eostoken'이라 명명하고 앞, 뒤로 추가하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e1fc772-dc23-4856-b05e-f019affc19b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "      <td>good quality dog food</td>\n",
       "      <td>sostoken good quality dog food</td>\n",
       "      <td>good quality dog food eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product arrived labeled jumbo salted peanuts p...</td>\n",
       "      <td>not as advertised</td>\n",
       "      <td>sostoken not as advertised</td>\n",
       "      <td>not as advertised eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>confection around centuries light pillowy citr...</td>\n",
       "      <td>delight says it all</td>\n",
       "      <td>sostoken delight says it all</td>\n",
       "      <td>delight says it all eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "      <td>cough medicine</td>\n",
       "      <td>sostoken cough medicine</td>\n",
       "      <td>cough medicine eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>great taffy</td>\n",
       "      <td>sostoken great taffy</td>\n",
       "      <td>great taffy eostoken</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                Summary  \\\n",
       "0  bought several vitality canned dog food produc...  good quality dog food   \n",
       "1  product arrived labeled jumbo salted peanuts p...      not as advertised   \n",
       "2  confection around centuries light pillowy citr...    delight says it all   \n",
       "3  looking secret ingredient robitussin believe f...         cough medicine   \n",
       "4  great taffy great price wide assortment yummy ...            great taffy   \n",
       "\n",
       "                    decoder_input                  decoder_target  \n",
       "0  sostoken good quality dog food  good quality dog food eostoken  \n",
       "1      sostoken not as advertised      not as advertised eostoken  \n",
       "2    sostoken delight says it all    delight says it all eostoken  \n",
       "3         sostoken cough medicine         cough medicine eostoken  \n",
       "4            sostoken great taffy            great taffy eostoken  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['Summary'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['Summary'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "00fbc3d7-691b-44fa-a658-98eb3b2c49ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더의 입력, 디코더의 입력과 레이블을 각각 저장\n",
    "encoder_input = np.array(data['Text'])\n",
    "decoder_input = np.array(data['decoder_input'])\n",
    "decoder_target = np.array(data['decoder_target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "92affa8e-63be-4321-a03f-6fab2c14b2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[61165 60938 37145 ... 45440 26023  1298]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분리\n",
    "indices = np.arange(encoder_input.shape[0])   \n",
    "np.random.shuffle(indices)\n",
    "print(indices)   # 순서가 섞인 정수 시퀀스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "904e9b65-34c4-4d1f-bba5-064c610667c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 시퀀스 순서를 데이터의 샘플 순서로 정의\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "89e3a5a6-e0e7-4ac7-ab4d-bc405a3ac6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 13163\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :',n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0d8f0405-3665-47c9-9bb9-2edfec226775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 52655\n",
      "훈련 레이블의 개수 : 52655\n",
      "테스트 데이터의 개수 : 13163\n",
      "테스트 레이블의 개수 : 13163\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "67ab90b0-d81f-49bc-8b0f-8d6ecb781d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩\n",
    "src_tokenizer = Tokenizer()\n",
    "src_tokenizer.fit_on_texts(encoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "58501dbe-d957-475e-ad42-f192563e4a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 31987\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 23700\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 8287\n",
      "단어 집합에서 희귀 단어의 비율: 74.09260011879826\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.383968496474902\n"
     ]
    }
   ],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab97b33-fbc6-4f7a-b57f-108bf26cb216",
   "metadata": {},
   "source": [
    "등장 빈도가 threshold 값인 7회 미만. 즉, 6회 이하인 단어들은 단어 집합에서 무려 70% 이상을 차지한다. 하지만, 실제로 훈련 데이터에서 등장 빈도로 차지하는 비중은 상대적으로 적은 수치인 3.39%밖에 되지 않는다. 여기서는 등장 빈도가 6회 이하인 단어들은 정수 인코딩 과정에서 배제시키고자 한다. 위에서 이를 제외한 단어 집합의 크기를 8,233으로 계산했는데, 저자는 깔끔한 값을 선호하여 이와 비슷한 값으로 단어 집합의 크기를 8000으로 제한한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8b199180-e6cd-4b8f-b5f6-1c7ece74c07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = 8000\n",
    "src_tokenizer = Tokenizer(num_words = src_vocab) \n",
    "src_tokenizer.fit_on_texts(encoder_input_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f2d85022-d69b-4603-8adc-34ce36d1d216",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9b8447fb-2aef-4116-bd4b-f7198cb47e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 10524\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 8150\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 2374\n",
      "단어 집합에서 희귀 단어의 비율: 77.44203724819461\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 5.940836959469056\n"
     ]
    }
   ],
   "source": [
    "threshold = 6\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "305443af-06d1-4469-8eb7-64e218e95e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_vocab = 2000\n",
    "tar_tokenizer = Tokenizer(num_words = tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4761f723-a7bf-4517-857c-adfcb01dc56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 130, 15], [1, 15, 19, 240], [1, 51, 63, 385, 319, 118], [1, 397, 948], [1, 29, 122]]\n"
     ]
    }
   ],
   "source": [
    "print(decoder_input_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e947a019-be5b-407d-815d-796d790f8d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[130, 15, 2], [15, 19, 240, 2], [51, 63, 385, 319, 118, 2], [397, 948, 2], [29, 122, 2]]\n"
     ]
    }
   ],
   "source": [
    "print(decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a018ec6b-99e8-4323-9d18-58062f7bc26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 1310\n",
      "삭제할 테스트 데이터의 개수 : 292\n"
     ]
    }
   ],
   "source": [
    "# 빈 샘플(empty samples) 제거\n",
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :',len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :',len(drop_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "13f8544c-02b8-4e47-9e72-ccbfaf9509f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 51345\n",
      "훈련 레이블의 개수 : 51345\n",
      "테스트 데이터의 개수 : 12871\n",
      "테스트 레이블의 개수 : 12871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\intown\\lib\\site-packages\\numpy\\lib\\function_base.py:4454: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = asarray(arr)\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = np.delete(encoder_input_train, drop_train, axis=0)\n",
    "decoder_input_train = np.delete(decoder_input_train, drop_train, axis=0)\n",
    "decoder_target_train = np.delete(decoder_target_train, drop_train, axis=0)\n",
    "\n",
    "encoder_input_test = np.delete(encoder_input_test, drop_test, axis=0)\n",
    "decoder_input_test = np.delete(decoder_input_test, drop_test, axis=0)\n",
    "decoder_target_test = np.delete(decoder_target_test, drop_test, axis=0)\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d6e38c44-58a6-4354-8d88-05dd06ddbdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩하기\n",
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen = text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen = text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen = summary_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen = summary_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen = summary_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen = summary_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ea16e0ea-7a48-4b52-a542-1321e9332416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq2seq + attention으로 요약 모델 설계 및 훈련\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2685726a-0aa4-448a-a000-5f989ab4bd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences = True, return_state = True, dropout = 0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state = [state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "929a86eb-1f79-433e-9193-16e6fab506e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 50)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 50, 128)      1024000     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 50, 256),    394240      ['embedding[0][0]']              \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 50, 256),    525312      ['lstm[0][0]']                   \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 128)    256000      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 50, 256),    525312      ['lstm_1[0][0]']                 \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, None, 256),  394240      ['embedding_1[0][0]',            \n",
      "                                 (None, 256),                     'lstm_2[0][1]',                 \n",
      "                                 (None, 256)]                     'lstm_2[0][2]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 2000)   514000      ['lstm_3[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,633,104\n",
      "Trainable params: 3,633,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation = 'softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "578e8b7c-3795-4c0d-a4b0-6ae3d1203072",
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/20.%20Text%20Summarization%20with%20Attention/attention.py\", filename=\"attention.py\")\n",
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1889860d-cda6-401e-bae5-fc4a307e7169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 50)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 50, 128)      1024000     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 50, 256),    394240      ['embedding[0][0]']              \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 50, 256),    525312      ['lstm[0][0]']                   \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 128)    256000      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 50, 256),    525312      ['lstm_1[0][0]']                 \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, None, 256),  394240      ['embedding_1[0][0]',            \n",
      "                                 (None, 256),                     'lstm_2[0][1]',                 \n",
      "                                 (None, 256)]                     'lstm_2[0][2]']                 \n",
      "                                                                                                  \n",
      " attention_layer (AttentionLaye  ((None, None, 256),  131328     ['lstm_2[0][0]',                 \n",
      " r)                              (None, None, 50))                'lstm_3[0][0]']                 \n",
      "                                                                                                  \n",
      " concat_layer (Concatenate)     (None, None, 512)    0           ['lstm_3[0][0]',                 \n",
      "                                                                  'attention_layer[0][0]']        \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, None, 2000)   1026000     ['concat_layer[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,276,432\n",
      "Trainable params: 4,276,432\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis = -1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "616811ed-6f6c-402a-b923-fc3e3ee33d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4823c43f-fadf-4763-8055-bf2a6fd4ff37",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "201/201 [==============================] - 2083s 10s/step - loss: 2.7097 - val_loss: 2.4074\n",
      "Epoch 2/50\n",
      "201/201 [==============================] - 2318s 12s/step - loss: 2.3844 - val_loss: 2.2549\n",
      "Epoch 3/50\n",
      "201/201 [==============================] - 2584s 13s/step - loss: 2.2352 - val_loss: 2.1510\n",
      "Epoch 4/50\n",
      "201/201 [==============================] - 2920s 15s/step - loss: 2.1246 - val_loss: 2.0775\n",
      "Epoch 5/50\n",
      "153/201 [=====================>........] - ETA: 10:51 - loss: 2.0438"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-ee4ec6f87319>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m history = model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train, \\\n\u001b[0;32m      3\u001b[0m           \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mencoder_input_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_input_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_target_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m           batch_size = 256, callbacks=[es], epochs = 50)\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\intown\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\intown\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1562\u001b[0m                         ):\n\u001b[0;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1564\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1565\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\intown\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\intown\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\intown\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\intown\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2495\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2496\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2497\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2499\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\intown\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1861\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1862\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1863\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1864\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\intown\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    505\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\intown\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 2)\n",
    "history = model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size = 256, callbacks=[es], epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0fece1b3-0b2e-415c-9449-b35ead90adbc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-25b0bccc3a1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3e2bd2b1-7e2c-4fdb-94cc-738282a6d1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq2seq + attention으로 요약 모델 테스트\n",
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음\n",
    "\n",
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4d307c29-8d16-468c-8705-d6f032df2cd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decoder_outputs2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-a32328f3efd8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 어텐션 함수\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdecoder_hidden_state_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_max_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mattn_out_inf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn_states_inf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattn_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdecoder_hidden_state_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_outputs2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdecoder_inf_concat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'concat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdecoder_outputs2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn_out_inf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'decoder_outputs2' is not defined"
     ]
    }
   ],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ab62fe3b-3c27-4512-a403-c99a74a4f1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if(sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc78203a-e389-4b3a-b558-403f209422e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    sentence=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            sentence = sentence + src_index_to_word[i]+' '\n",
    "    return sentence\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    sentence=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            sentence = sentence + tar_index_to_word[i] + ' '\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8092be-d253-4468-bba3-83df53d46d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(500, 1000):\n",
    "    print(\"원문 : \",seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약문 :\",seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약문 :\",decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intown_kernel",
   "language": "python",
   "name": "intown_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
