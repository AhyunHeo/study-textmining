{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02b3bba5",
   "metadata": {},
   "source": [
    "#### 단어표현(Word Representation) 방법 분류 참고 사이트\n",
    "https://heytech.tistory.com/335\n",
    "* * *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e36d3ef",
   "metadata": {},
   "source": [
    "- 단어 표현\n",
    "    - 국소/이산 표현: 단어에 특정값 또는 숫자 매핑\n",
    "    - 분산/연속 표현: 주변 단어를 이용하여 표현 (LSA, LDA, Word2vec, FastText, GloVe)\n",
    "    \n",
    "- 문장/문서 표현\n",
    "    - Bag of Words(BoW) : 단어들의 순서를 무시, 단어(n-gram 포함)들의 출현을 이용하여 텍스트자료를 수치화 하는 방법\n",
    "    - 벡터공간모형(Vector Space model): 문서의 단어들의 여부 (또는 빈도)를 단어집합(딕션너리) 크기 만큼의 벡터로 표현\n",
    "    - 문서단어행렬(Document-Term Matrix; DTM): 전체 문서집합에 대하여 각 문서를 BoW모형과 벡터공간모형을 이용하여 같은 길이의 벡터를 생성하고, 이들을 결합하여 행렬로 표시"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2af9ec0",
   "metadata": {},
   "source": [
    "### 1. BoW 모형을 이용한 문서단어행렬(DTM)\n",
    "\n",
    "#### 1) CountVectorizer : 빈도기반"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99b0614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer    # CountVectorizer : 빈도기반\n",
    "\n",
    "corpus = [\n",
    "    \"철수는 통계학과에 다닌다.\",\n",
    "    \"빅데이터 분석에 필요한 것은 통계학적 지식과 프로그래밍 능력이다.\",\n",
    "    \"4차산업의 핵심기술로 인공지능과 빅데이터가 있다.\",\n",
    "    \"텍스트자료는 빅데이터에서 중요한 재료이다.\"\n",
    "    ]\n",
    "vector = CountVectorizer() # default: 길이가 2이상인 단어만 추출 \n",
    "                           # 띄어쓰기만을 기준"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95bd695f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# corpus 문서별 단어를 정수로 매핑하고, 단어의 빈도 수를 희소행렬(sparse martrix)로 변환\n",
    "dtm = vector.fit_transform(corpus)\n",
    "dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b973ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4차산업의</th>\n",
       "      <th>것은</th>\n",
       "      <th>능력이다</th>\n",
       "      <th>다닌다</th>\n",
       "      <th>분석에</th>\n",
       "      <th>빅데이터</th>\n",
       "      <th>빅데이터가</th>\n",
       "      <th>빅데이터에서</th>\n",
       "      <th>인공지능과</th>\n",
       "      <th>있다</th>\n",
       "      <th>재료이다</th>\n",
       "      <th>중요한</th>\n",
       "      <th>지식과</th>\n",
       "      <th>철수는</th>\n",
       "      <th>텍스트자료는</th>\n",
       "      <th>통계학과에</th>\n",
       "      <th>통계학적</th>\n",
       "      <th>프로그래밍</th>\n",
       "      <th>필요한</th>\n",
       "      <th>핵심기술로</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   4차산업의  것은  능력이다  다닌다  분석에  빅데이터  빅데이터가  빅데이터에서  인공지능과  있다  재료이다  중요한  지식과  \\\n",
       "0      0   0     0    1    0     0      0       0      0   0     0    0    0   \n",
       "1      0   1     1    0    1     1      0       0      0   0     0    0    1   \n",
       "2      1   0     0    0    0     0      1       0      1   1     0    0    0   \n",
       "3      0   0     0    0    0     0      0       1      0   0     1    1    0   \n",
       "\n",
       "   철수는  텍스트자료는  통계학과에  통계학적  프로그래밍  필요한  핵심기술로  \n",
       "0    1       0      1     0      0    0      0  \n",
       "1    0       0      0     1      1    1      0  \n",
       "2    0       0      0     0      0    0      1  \n",
       "3    0       1      0     0      0    0      0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tf = pd.DataFrame(dtm.toarray(), columns = vector.get_feature_names_out())\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5edf637b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'철수는': 13,\n",
       " '통계학과에': 15,\n",
       " '다닌다': 3,\n",
       " '빅데이터': 5,\n",
       " '분석에': 4,\n",
       " '필요한': 18,\n",
       " '것은': 1,\n",
       " '통계학적': 16,\n",
       " '지식과': 12,\n",
       " '프로그래밍': 17,\n",
       " '능력이다': 2,\n",
       " '4차산업의': 0,\n",
       " '핵심기술로': 19,\n",
       " '인공지능과': 8,\n",
       " '빅데이터가': 6,\n",
       " '있다': 9,\n",
       " '텍스트자료는': 14,\n",
       " '빅데이터에서': 7,\n",
       " '중요한': 11,\n",
       " '재료이다': 10}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.vocabulary_    # 단어: 정수인덱스로 구성된 딕션너리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e413e656",
   "metadata": {},
   "source": [
    "- 불용어 제거 후 문서단어행렬(DTM) 만들기 (사용자정의 불용어)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e186fa1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 0 1]\n",
      " [1 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer   # CountVectorizer : 빈도기반\n",
    "\n",
    "text=[\"Family is not an important thing\",\"It's everything.\"]\n",
    "vect = CountVectorizer(stop_words=[\"the\", \"a\", \"an\", \"is\", \"not\"]) # 불용어의 사용자 정의\n",
    "m = vect.fit_transform(text) # 단어의 빈도 수를 희소행렬로 받아옴\n",
    "\n",
    "print(m.toarray()) # 희소행렬을 numpy array로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22147569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'family': 1, 'important': 2, 'thing': 4, 'it': 3, 'everything': 0}\n"
     ]
    }
   ],
   "source": [
    "print(vect.vocabulary_) # 단어와 매치되는 정수 인덱스 딕션너리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3aaaa5",
   "metadata": {},
   "source": [
    "- 불용어 제거 후 문서단어행렬(DTM) 만들기 (```CountVectorizer```에서 제공하는 자체 불용어)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d2785e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1]\n",
      " [0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "print(vect.fit_transform(text).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d46ca180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'family': 0, 'important': 1, 'thing': 2}\n"
     ]
    }
   ],
   "source": [
    "print(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364761cc",
   "metadata": {},
   "source": [
    "- 불용어 제거 후 문서단어행렬(DTM) 만들기 (nltk에서 지원하는 불용어)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b5a17c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1]\n",
      " [1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "text=[\"Family is not an important thing\",\"It's everything.\"]\n",
    "sw = stopwords.words(\"english\")\n",
    "vect = CountVectorizer(stop_words =sw)\n",
    "\n",
    "print(vect.fit_transform(text).toarray()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4b22906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'family': 1, 'important': 2, 'thing': 3, 'everything': 0}\n"
     ]
    }
   ],
   "source": [
    "print(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed431df",
   "metadata": {},
   "source": [
    "#### 2) TfidfVectorizer : TF-IDF 기반"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f1dcb06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.57735027, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.57735027, 0.        ,\n",
       "        0.57735027, 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.35355339, 0.35355339, 0.        , 0.35355339,\n",
       "        0.35355339, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.35355339, 0.        , 0.        ,\n",
       "        0.        , 0.35355339, 0.35355339, 0.35355339, 0.        ],\n",
       "       [0.4472136 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.4472136 , 0.        , 0.4472136 , 0.4472136 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.4472136 ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.5       , 0.        , 0.        ,\n",
       "        0.5       , 0.5       , 0.        , 0.        , 0.5       ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [\n",
    "    \"철수는 통계학과에 다닌다.\",\n",
    "    \"빅데이터 분석에 필요한 것은 통계학적 지식과 프로그래밍 능력이다.\",\n",
    "    \"4차산업의 핵심기술로 인공지능과 빅데이터가 있다.\",\n",
    "    \"텍스트자료는 빅데이터에서 중요한 재료이다.\"\n",
    "    ]\n",
    "tfidfv = TfidfVectorizer().fit_transform(corpus)\n",
    "tfidfv.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99b58ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.57735027 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.57735027 0.         0.57735027 0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.35355339 0.35355339 0.         0.35355339 0.35355339\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.35355339 0.         0.         0.         0.35355339 0.35355339\n",
      "  0.35355339 0.        ]\n",
      " [0.4472136  0.         0.         0.         0.         0.\n",
      "  0.4472136  0.         0.4472136  0.4472136  0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.4472136 ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.5        0.         0.         0.5        0.5\n",
      "  0.         0.         0.5        0.         0.         0.\n",
      "  0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidfv = TfidfVectorizer().fit(corpus)\n",
    "print(tfidfv.transform(corpus).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f198d65",
   "metadata": {},
   "source": [
    "### 2. 한글처리\n",
    "#### 1) 형태소 분석\n",
    "- morph: 형태소를 분리하여 단어 추출\n",
    "- nouns: 명사에 해당되는 단어 추출\n",
    "- pos: 단어 + 형태소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92afd83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('철수', 'Noun'), ('는', 'Josa'), ('통계', 'Noun'), ('학과', 'Noun'), ('에', 'Josa'), ('다니다', 'Verb'), ('.', 'Punctuation')]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "corpus = [\n",
    "    \"철수는 통계학과에 다닌다.\",\n",
    "    \"빅데이터 분석에 필요한 것은 통계학적 지식과 프로그래밍 능력이다.\",\n",
    "    \"4차산업의 핵심기술로 인공지능과 빅데이터가 있다.\",\n",
    "    \"텍스트자료는 빅데이터에서 중요한 재료이다.\"\n",
    "    ]\n",
    "\n",
    "okt = Okt()\n",
    "okt_pos = okt.pos(corpus[0],\n",
    "        norm=True,   # 정규화(normalization)\n",
    "        stem=True    # 어간추출(stemming)\n",
    "        )\n",
    "print(okt_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9d11e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['철수', '통계', '학과', '다니다']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 형태소(POS)가 명사,동사,알파벳,숫자에 해당되는 단어 추출\n",
    "# 정규화(normalization) 어간추출(stemming) 처리\n",
    "def tokenizer(raw_texts, pos=[\"Noun\",\"Alpha\",\"Verb\",\"Number\"], stopword=[]):\n",
    "    okt_pos = okt.pos(raw_texts, \n",
    "            norm=True,   # 정규화(normalization)\n",
    "            stem=True    # 어간추출(stemming)\n",
    "            )\n",
    "    o = [word for word, tag in okt_pos if len(word) > 1 and tag in pos and word not in stopword]\n",
    "    return(o)\n",
    "\n",
    "tokenizer(corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b402e3",
   "metadata": {},
   "source": [
    "- TF-IDF 기반 DTM  (해석참고: https://heytech.tistory.com/337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35eabe16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heo\\.conda\\envs\\intown1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.5       , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.5       , 0.        , 0.5       , 0.        ,\n",
       "        0.        , 0.5       , 0.        ],\n",
       "       [0.        , 0.43003652, 0.        , 0.43003652, 0.27448674,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.43003652, 0.        , 0.        , 0.        , 0.43003652,\n",
       "        0.43003652, 0.        , 0.        ],\n",
       "       [0.43003652, 0.        , 0.        , 0.        , 0.27448674,\n",
       "        0.43003652, 0.43003652, 0.        , 0.        , 0.43003652,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.43003652],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.34578314,\n",
       "        0.        , 0.        , 0.5417361 , 0.5417361 , 0.        ,\n",
       "        0.        , 0.        , 0.5417361 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorize = TfidfVectorizer(\n",
    "    tokenizer=tokenizer, # 문장에 대한 tokenizer (위에 정의한 함수 이용)\n",
    "    min_df=1,            # 단어가 출현하는 최소 문서의 개수\n",
    "    sublinear_tf=True    # tf값에 1+log(tf)를 적용하여 tf값이 무한정 커지는 것을 막음\n",
    ")\n",
    "\n",
    "X = vectorize.fit_transform(corpus)\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9220a6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>기술</th>\n",
       "      <th>능력</th>\n",
       "      <th>다니다</th>\n",
       "      <th>분석</th>\n",
       "      <th>빅데이터</th>\n",
       "      <th>산업</th>\n",
       "      <th>인공</th>\n",
       "      <th>자료</th>\n",
       "      <th>재료</th>\n",
       "      <th>지능</th>\n",
       "      <th>지식</th>\n",
       "      <th>철수</th>\n",
       "      <th>텍스트</th>\n",
       "      <th>통계</th>\n",
       "      <th>통계학</th>\n",
       "      <th>프로그래밍</th>\n",
       "      <th>학과</th>\n",
       "      <th>핵심</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.430037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.430037</td>\n",
       "      <td>0.274487</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.430037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.430037</td>\n",
       "      <td>0.430037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.430037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.274487</td>\n",
       "      <td>0.430037</td>\n",
       "      <td>0.430037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.430037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.430037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.345783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.541736</td>\n",
       "      <td>0.541736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.541736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         기술        능력  다니다        분석      빅데이터        산업        인공        자료  \\\n",
       "0  0.000000  0.000000  0.5  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.430037  0.0  0.430037  0.274487  0.000000  0.000000  0.000000   \n",
       "2  0.430037  0.000000  0.0  0.000000  0.274487  0.430037  0.430037  0.000000   \n",
       "3  0.000000  0.000000  0.0  0.000000  0.345783  0.000000  0.000000  0.541736   \n",
       "\n",
       "         재료        지능        지식   철수       텍스트   통계       통계학     프로그래밍   학과  \\\n",
       "0  0.000000  0.000000  0.000000  0.5  0.000000  0.5  0.000000  0.000000  0.5   \n",
       "1  0.000000  0.000000  0.430037  0.0  0.000000  0.0  0.430037  0.430037  0.0   \n",
       "2  0.000000  0.430037  0.000000  0.0  0.000000  0.0  0.000000  0.000000  0.0   \n",
       "3  0.541736  0.000000  0.000000  0.0  0.541736  0.0  0.000000  0.000000  0.0   \n",
       "\n",
       "         핵심  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.430037  \n",
       "3  0.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Term Freqeuncy\n",
    "import pandas as pd\n",
    "tfidf = pd.DataFrame(X.toarray(), columns = vectorize.get_feature_names_out())\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b0aa737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "기술       1\n",
       "능력       1\n",
       "다니다      1\n",
       "분석       1\n",
       "빅데이터     3\n",
       "산업       1\n",
       "인공       1\n",
       "자료       1\n",
       "재료       1\n",
       "지능       1\n",
       "지식       1\n",
       "철수       1\n",
       "텍스트      1\n",
       "통계       1\n",
       "통계학      1\n",
       "프로그래밍    1\n",
       "학과       1\n",
       "핵심       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Document Frequency \n",
    "freq = tfidf.astype(bool).sum(axis = 0)\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb2ba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 결과를 통해 '빅데이터'라는 단어만 3개의 문서에서 등장한 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515f495f",
   "metadata": {},
   "source": [
    "### 3. 문서 유사도(Document Similarity)\n",
    "- 유클리드 거리(euclidean_distances), 코사인유사도(cosine similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a1a58f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.43003652, 0.        , 0.43003652, 0.27448674,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.43003652, 0.        , 0.        , 0.        , 0.43003652,\n",
       "        0.43003652, 0.        , 0.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# corpus = [\n",
    "#0    \"철수는 통계학과에 다닌다.\",\n",
    "#1    \"빅데이터 분석에 필요한 것은 통계학적 지식과 프로그래밍 능력이다.\",\n",
    "#2    \"4차산업의 핵심기술로 인공지능과 빅데이터가 있다.\",\n",
    "#3    \"텍스트자료는 빅데이터에서 중요한 재료이다.\"\n",
    "#    ]\n",
    "\n",
    "X[1].toarray()    # 2번째 문서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b85b4c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.41421356]]\n",
      "[[1.41421356]]\n",
      "[[1.41421356]]\n",
      "[[1.35989487]]\n",
      "[[1.34542715]]\n",
      "[[1.34542715]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "# 유클리드 거리 계산\n",
    "print(euclidean_distances(X[0], X[1]))\n",
    "print(euclidean_distances(X[0], X[2]))\n",
    "print(euclidean_distances(X[0], X[3]))\n",
    "print(euclidean_distances(X[1], X[2]))\n",
    "print(euclidean_distances(X[1], X[3]))\n",
    "print(euclidean_distances(X[2], X[3]))\n",
    "\n",
    "# 유클리드 거리가 가까울수록 문서간 유사하다고 해석할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ecf445e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.07534297]]\n",
      "[[0.09491289]]\n",
      "[[0.09491289]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 코사인 유사도\n",
    "print(cosine_similarity(X[0], X[1]))\n",
    "print(cosine_similarity(X[0], X[2]))\n",
    "print(cosine_similarity(X[0], X[3]))\n",
    "print(cosine_similarity(X[1], X[2]))\n",
    "print(cosine_similarity(X[1], X[3]))\n",
    "print(cosine_similarity(X[2], X[3]))\n",
    "\n",
    "# 코사인 유사도는 1에 가까울수록 두 벡터가 유사하다고 해석하며, \n",
    "# 문서의 길이가 다른 경우에도 비교적 공정하게 비교할 수 있다는 장점이 있다. \n",
    "# 두 벡터 사이의 각도가 0도일 때 코사인 유사도가 최댓값인 1을 갖는다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intown1_kernel",
   "language": "python",
   "name": "intown1_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
